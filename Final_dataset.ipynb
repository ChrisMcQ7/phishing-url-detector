{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7d53721-d6c6-4c80-b0ce-fd4a64b06f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final dataset saved as 'final_dataset.csv'\n",
      "type\n",
      "legitimate    50000\n",
      "phishing      50000\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   url     100000 non-null  object\n",
      " 1   type    100000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "\n",
      "ðŸ“Š VALIDATION CHECKS\n",
      "\n",
      "Missing values:\n",
      " url     0\n",
      "type    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate URLs: 0\n",
      "\n",
      "Class distribution:\n",
      " type\n",
      "legitimate    50000\n",
      "phishing      50000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Phishing URL protocol breakdown:\n",
      "https:// : 49057\n",
      "http://  : 943\n",
      "Other    : 0\n",
      "\n",
      "Preview of cleaned dataset:\n",
      "                                                 url        type\n",
      "0  https://www.a-trains.com/shop/kcchidvd/cab_rid...  legitimate\n",
      "1  https://www.simpsons.wikia.com/wiki/stark_ravi...  legitimate\n",
      "2  https://docs.google.com/presentation/d/e/2pacx...    phishing\n",
      "3  https://www.nme.com/awards/video/id/nhs94cpbix...  legitimate\n",
      "4  https://www.public.fotki.com/pikliz/haiti_voll...  legitimate\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load datasets\n",
    "df_legit = pd.read_csv(\"url-dataset.csv\")\n",
    "df_phish = pd.read_csv(\"phishing-url.csv\")\n",
    "\n",
    "# 2. Normalize column headers to lowercase\n",
    "df_legit.rename(columns=lambda x: x.strip().lower(), inplace=True)\n",
    "df_phish.rename(columns=lambda x: x.strip().lower(), inplace=True)\n",
    "\n",
    "# 3. Normalize URL and type fields (strip whitespace, lowercase)\n",
    "for df in [df_legit, df_phish]:\n",
    "    df['url'] = df['url'].astype(str).str.strip().str.lower()\n",
    "    df['type'] = df['type'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# 4. Drop missing or duplicate rows\n",
    "df_legit.dropna(subset=['url', 'type'], inplace=True)\n",
    "df_phish.dropna(subset=['url', 'type'], inplace=True)\n",
    "\n",
    "df_legit.drop_duplicates(subset='url', inplace=True)\n",
    "df_phish.drop_duplicates(subset='url', inplace=True)\n",
    "\n",
    "# 5. Separate phishing URLs based on protocol\n",
    "phish_https = df_phish[(df_phish['type'] == 'phishing') & df_phish['url'].str.startswith(\"https://\")]\n",
    "phish_other = df_phish[(df_phish['type'] == 'phishing') & ~df_phish['url'].str.startswith(\"https://\")]\n",
    "\n",
    "# 6. Combine to make 50,000 phishing URLs (or as many as available)\n",
    "needed = 50000 - len(phish_https)\n",
    "if needed > 0:\n",
    "    fill_phish = phish_other.sample(n=min(needed, len(phish_other)), random_state=42)\n",
    "    final_phish = pd.concat([phish_https, fill_phish])\n",
    "else:\n",
    "    final_phish = phish_https.sample(n=50000, random_state=42)\n",
    "\n",
    "# 7. Sample 50,000 legitimate URLs\n",
    "final_legit = df_legit[df_legit['type'] == 'legitimate'].sample(n=50000, random_state=42)\n",
    "\n",
    "# 8. Combine and shuffle\n",
    "final_df = pd.concat([final_phish, final_legit]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 9. Save to file\n",
    "final_df.to_csv(\"final_dataset.csv\", index=False)\n",
    "print(\"âœ… Final dataset saved as 'final_dataset.csv'\")\n",
    "print(final_df['type'].value_counts())\n",
    "print(final_df.info())\n",
    "\n",
    "\n",
    "# âœ… DATASET VALIDATION\n",
    "# -----------------------\n",
    "\n",
    "print(\"\\nðŸ“Š VALIDATION CHECKS\\n\")\n",
    "\n",
    "# 1. Check for missing values\n",
    "missing = final_df.isnull().sum()\n",
    "print(\"Missing values:\\n\", missing)\n",
    "\n",
    "# 2. Check for duplicate URLs\n",
    "duplicates = final_df.duplicated(subset='url').sum()\n",
    "print(\"\\nDuplicate URLs:\", duplicates)\n",
    "\n",
    "# 3. Check class distribution\n",
    "print(\"\\nClass distribution:\\n\", final_df['type'].value_counts())\n",
    "\n",
    "# 4. Check protocol distribution in phishing URLs\n",
    "phish_urls = final_df[final_df['type'] == 'phishing']['url']\n",
    "https_count = phish_urls.str.startswith(\"https://\").sum()\n",
    "http_count = phish_urls.str.startswith(\"http://\").sum()\n",
    "other_count = len(phish_urls) - https_count - http_count\n",
    "\n",
    "print(\"\\nPhishing URL protocol breakdown:\")\n",
    "print(f\"https:// : {https_count}\")\n",
    "print(f\"http://  : {http_count}\")\n",
    "print(f\"Other    : {other_count}\")\n",
    "\n",
    "# 5. Quick look at dataset\n",
    "print(\"\\nPreview of cleaned dataset:\")\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe73dc-b1b8-406b-a7d7-ea672dbcc984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
